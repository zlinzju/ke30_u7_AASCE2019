{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "import os, gc, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use gpu\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if gpu:\n",
    "    print(\"use gpu\")\n",
    "    #device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_unet = torch.load('E:/Workspace/ke30_u7_AASCE2019/resunet_mean.pth')\n",
    "\n",
    "net = res_unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostNetChallgeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, names, transform=None):\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "          \n",
    "        for i, path in enumerate(names):\n",
    "            image_name = path.name\n",
    "            self.labels.append(image_name)\n",
    "            origin_image = cv.imread(str(path),0)\n",
    "            target_height = 512\n",
    "            target_width = 256\n",
    "            image = np.zeros((target_height, target_width), np.uint8)\n",
    "            cv.resize(origin_image, (target_width, target_height), image)\n",
    "            \n",
    "            image = np.reshape(image, (1, image.shape[0], image.shape[1]))\n",
    "            image_tensor = torch.from_numpy(image).float()\n",
    "            \n",
    "            self.images.append(image_tensor)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero the parameter gradients\n",
    "#optimizer.zero_grad()\n",
    "from pathlib import Path\n",
    "p = Path('.')\n",
    "test_images = list(p.glob('./test/*.jpg'))\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches(testing):  25\n"
     ]
    }
   ],
   "source": [
    "target_data = BoostNetChallgeDataset(test_images)\n",
    "  \n",
    "batch = 4\n",
    "target_loader = torch.utils.data.DataLoader(target_data, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "print(\"number of batches(testing): \",len(target_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-1.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-10.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-11.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-12.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-13.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-14.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-15.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-16.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-17.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-18.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-19.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-2.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-20.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-21.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-22.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-23.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-24.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-25.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-26.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-27.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-28.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-29.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-3.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-30.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-31.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-32.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-33.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-34.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-35.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-36.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-37.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-38.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-39.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-4.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-40.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-41.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-42.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-43.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-44.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-45.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-46.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-47.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-48.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-49.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-5.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-50.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-51.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-52.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-53.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-54.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-55.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-56.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-57.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-58.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-59.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-6.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-60.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-61.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-62.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-63.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-64.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-65.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-66.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-67.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-68.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-69.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-7.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-70.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-71.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-72.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-73.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-74.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-75.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-76.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-77.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-78.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-79.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-8.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-80.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-81.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-82.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-83.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-84.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-85.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-86.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-87.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-88.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-89.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-9.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-90.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-91.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-92.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-93.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-94.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-95.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-96.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-97.jpg\n",
      "(512, 256)\n",
      "E:/Workspace/ke30_u7_AASCE2019/test/resized/01-July-2019-98.jpg\n",
      "(512, 256)\n"
     ]
    }
   ],
   "source": [
    "for path in test_images:\n",
    "  image_name = path.name\n",
    "  origin_image = cv.imread(str(path),0)\n",
    "  target_height = 512\n",
    "  target_width = 256\n",
    "  image = np.zeros((target_height, target_width), np.uint8)\n",
    "  cv.resize(origin_image, (target_width, target_height), image)\n",
    "  dest = \"E:/Workspace/ke30_u7_AASCE2019/test/resized/\" + image_name\n",
    "  print(dest)\n",
    "  print(image.shape)\n",
    "  cv.imwrite(dest, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wlgq\\AppData\\Local\\conda\\conda\\envs\\pt\\lib\\site-packages\\torch\\nn\\functional.py:2479: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "#dataiter = iter(target_loader)\n",
    "land_pred = np.empty([98, 136])\n",
    "image_names = []\n",
    "  \n",
    "index = 0\n",
    "for images, labels in target_loader:\n",
    "  batch, channel, height, width = images.shape\n",
    "  ret = net(images.to(device))\n",
    "  for i in range(batch):\n",
    "    predict = ret[i]\n",
    "    lineIndex = index + i;\n",
    "    image_names.append(labels[i])\n",
    "    #print(image_names)\n",
    "    point_num = len(predict)\n",
    "    #print(\"copy data for line : \" + str(lineIndex+ 1))\n",
    "    for j in range(point_num):\n",
    "      land_pred[lineIndex,j]= predict[j]\n",
    "      \n",
    "  index+=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"E:/Workspace/ke30_u7_AASCE2019/test/landmarks.csv\", land_pred, delimiter=\",\", fmt=\"%1.5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:/Workspace/ke30_u7_AASCE2019/test/filenames.csv\",'w',newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    for name in image_names:\n",
    "      wr.writerow([name,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "land_array = []\n",
    "images=[]\n",
    "p2 = []\n",
    "width = 256\n",
    "height = 512\n",
    "mat_out = 'E:/Workspace/ke30_u7_AASCE2019/test/matfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = csv.reader(open('E:/Workspace/ke30_u7_AASCE2019/test/landmarks.csv', 'r'))\n",
    "for i, land in enumerate(landmarks):\n",
    "       land_array.append(land)\n",
    "len(land_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(images):\n",
    "    point_num = len(land_array[i]) // 2\n",
    "    predict = land_array[i]\n",
    "    points = np.empty((point_num,2))\n",
    "    for j in range(point_num):\n",
    "        left = int(float(predict[j]) * width)\n",
    "        right = int(float(predict[j + point_num])* height)\n",
    "        points[j] = [left,right]\n",
    "                    \n",
    "    data = {'p2' : points.tolist()}\n",
    "    filename = mat_out +\"/\"+ name[0] +\".mat\"\n",
    "    mat4py.savemat(filename, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
